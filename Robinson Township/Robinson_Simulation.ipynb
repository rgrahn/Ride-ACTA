{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime as dt\n",
    "import time\n",
    "import networkx as nx\n",
    "import osmnx as ox\n",
    "from itertools import permutations\n",
    "# For base case simulation\n",
    "import baseCaseSimulation as baseCase\n",
    "from baseCaseSimulation import *\n",
    "import vehicleMatching as vm\n",
    "from vehicleMatching import *\n",
    "# For simulation case\n",
    "import UPDATE_RouteSimClass as simul\n",
    "from UPDATE_RouteSimClass import *\n",
    "import UPDATE_RouteRiderVanClass as rv\n",
    "from UPDATE_RouteRiderVanClass import *\n",
    "os.chdir(\"C:/Users/Rick/Desktop/Research/RideACTA_RAMP/Data/RideACTA/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ---------------------------- Load Data ----------------------------------------------\n",
    "\n",
    "#    Load in all the trajectory and ridership data for May 1, 2019 - Aug 1, 2019\n",
    "\n",
    "# -------------------------------------------------------------------------------------\n",
    "trajFile = \"1b_filteredTrajWithFreeway.csv\"\n",
    "riderFile = '2f_finalRidershipHighwayFilter.csv'\n",
    "travelTimesFile = '3e_medTravTimes.csv'\n",
    "\n",
    "# Load trajectories for base case simulation\n",
    "def loadTrajForBaseCase(trajFile):\n",
    "    trajData = pd.read_csv(trajFile)\n",
    "    trajData = trajData.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1)\n",
    "    trajData = trajData[trajData['month'].isin([5, 6, 7])]\n",
    "    trajData['datetime'] = pd.to_datetime(trajData['datetime'])\n",
    "    return trajData\n",
    "\n",
    "def loadRiderData(riderFile):\n",
    "    riderData = pd.read_csv(riderFile)\n",
    "    riderData = riderData.drop('Unnamed: 0', axis = 1)\n",
    "    riderData = riderData[riderData['month'].isin([5, 6, 7])]\n",
    "    riderData['destination_poi'] = riderData['destination_poi'].astype(int)\n",
    "    riderData['origin_timestamp'] = pd.to_datetime(riderData['origin_timestamp'])\n",
    "    riderData['pending_time'] = pd.to_datetime(riderData['pending_time'])\n",
    "    riderData['pending_sec'] = riderData['pending_time'].apply(lambda row: row.hour*3600 + row.minute*60 + row.second)\n",
    "    riderData['destination_poi'] = riderData['destination_poi'].astype(int)\n",
    "    riderData['od_pair'] = riderData['origin_poi'].astype(str) + ', ' + riderData['destination_poi'].astype(str)\n",
    "    riderData['vehicle'] = riderData['vehicle'].astype(int)\n",
    "    deltaTime2 = 15\n",
    "    riderData['timePeriod1'] = riderData['origin_timestamp'].apply(lambda row: dt.datetime(row.year, row.month, row.day, row.hour, \\\n",
    "                                                             deltaTime2*(row.minute // deltaTime2))).dt.strftime('%H:%M:%S')\n",
    "    return riderData\n",
    "\n",
    "def loadTravTimesForRuleBasedSimulation(travelTimesFile):\n",
    "    travTimes = pd.read_csv(travelTimesFile)\n",
    "    travTimes = travTimes.drop(['Unnamed: 0'], axis = 1)\n",
    "    travTimes['median_x'] = travTimes['median_x'].astype(int)\n",
    "    new = travTimes['OD_string'].str.split(', ', n=1, expand=True)\n",
    "    travTimes['POI'] = new[0].astype(int)\n",
    "    travTimes['dest_POI'] = new[1].astype(int)\n",
    "    return travTimes\n",
    "\n",
    "def createGraph(travTimes, currentTimePeriod):\n",
    "    baseTime = '6:00:00'\n",
    "    # create column of time differences between current time and travel time\n",
    "    travTimes.loc[:,'currentTime'] = abs((pd.to_timedelta(currentTimePeriod).total_seconds() - \\\n",
    "                                                pd.to_timedelta(baseTime).total_seconds()) - \\\n",
    "                                               (pd.to_timedelta(travTimes.loc[:,'timePeriod']).dt.total_seconds() - \\\n",
    "                                                pd.to_timedelta(baseTime).total_seconds()))\n",
    "    # Find the closest time (either before or after) to determine travel time between two given nodes\n",
    "    a = travTimes.groupby(['OD_string']).apply(lambda travTimes: travTimes['currentTime'].idxmin())\n",
    "    # Filter the travel times based on the time-dependent travel times\n",
    "    timeDependentTravTimes = travTimes.loc[a, :].reset_index(drop=True)\n",
    "    # Create the graph for the specific time-dependent travel times\n",
    "    G = nx.from_pandas_edgelist(timeDependentTravTimes, source = 'POI', target = 'dest_POI', \\\n",
    "                                edge_attr = 'median_x', create_using = nx.DiGraph())\n",
    "    return G\n",
    "\n",
    "# Create time dependent network from median travel times\n",
    "def createTravTimeDict(travTimes):\n",
    "    timeDepTravTime = dict()\n",
    "    timeList1 = [f'0{hour}:{minute}:00' for hour in list(range(6,10)) for minute in ('00','15','30','45')]\n",
    "    timeList2 = [f'{hour}:{minute}:00' for hour in list(range(10,24)) for minute in ('00','15','30','45')]\n",
    "    timeList3 = timeList1 + timeList2\n",
    "    for currentTime in timeList3:\n",
    "        G = createGraph(travTimes, currentTime)\n",
    "        timeDepTravTime[currentTime] = G\n",
    "    return timeDepTravTime\n",
    "\n",
    "trajData = loadTrajForBaseCase(trajFile)\n",
    "riderData = loadRiderData(riderFile)\n",
    "travTimes = loadTravTimesForRuleBasedSimulation(travelTimesFile)\n",
    "timeDepTravTime = createTravTimeDict(travTimes)\n",
    "newDF = riderData[['ride_id', 'orig_sec']].copy()\n",
    "origTimeDict = newDF.set_index('ride_id').to_dict()\n",
    "riderTimeDict = origTimeDict['orig_sec']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is used to run the base case simulation based on actual vehicle trajectories. This is very approximate and some of the requests will have to be dropped from the analysis based on infeasible pickup/dropoff locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Do base case simulation\n",
    "import baseCaseSimulation as baseCase\n",
    "from baseCaseSimulation import *\n",
    "import vehicleMatching as vm\n",
    "from vehicleMatching import *\n",
    "\n",
    "importlib.reload(baseCase)\n",
    "importlib.reload(vm)\n",
    "\n",
    "# Run simulation for weekdays in July 2019\n",
    "simulDates = ['2019-07-01','2019-07-03','2019-07-05',\\\n",
    "             '2019-07-08','2019-07-09','2019-07-10','2019-07-11','2019-07-12',\\\n",
    "             '2019-07-15','2019-07-16','2019-07-17','2019-07-18','2019-07-19',\\\n",
    "             '2019-07-22','2019-07-23','2019-07-24','2019-07-25','2019-07-26']\n",
    "\n",
    "# Van Ids from Traj File\n",
    "trajIkeaVehList = [1237, 1533, 1535]\n",
    "# Van Ids from Rider File\n",
    "riderIkeaVehList = [2008, 2064, 2068]\n",
    "# Run Simulation\n",
    "baseCaseResults, requestsDict = runBaseCaseForMultipleDates(trajData, riderData, simulDates, riderIkeaVehList, trajIkeaVehList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block defines the simulation scenario. This is based on vans making decisions based on the minimal marginal cost for each additional rider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import UPDATE_RouteSimClass as simul\n",
    "from UPDATE_RouteSimClass import *\n",
    "import UPDATE_RouteRiderVanClass as rv\n",
    "from UPDATE_RouteRiderVanClass import *\n",
    "\n",
    "importlib.reload(simul)\n",
    "importlib.reload(rv)\n",
    "\n",
    "# Calculate haversine distances\n",
    "def haversine(coord1, coord2):\n",
    "    R = 6372800  # Earth radius in meters\n",
    "    lat1, lon1 = coord1\n",
    "    lat2, lon2 = coord2\n",
    "    \n",
    "    phi1, phi2 = math.radians(lat1), math.radians(lat2) \n",
    "    dphi       = math.radians(lat2 - lat1)\n",
    "    dlambda    = math.radians(lon2 - lon1)\n",
    "    \n",
    "    a = math.sin(dphi/2)**2 + \\\n",
    "        math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2\n",
    "    return 2*R*math.atan2(math.sqrt(a), math.sqrt(1 - a))*3.28084 #convert to feet\n",
    "\n",
    "# Find van start times for the ikea vehicles\n",
    "def findIkeaStartTime(trajInfo):\n",
    "    ikea = (40.452828, -80.168373)\n",
    "    vanStartTime = dict()\n",
    "    for vehicle in trajInfo['vehicle_id'].unique():\n",
    "        filtData = trajInfo[trajInfo['vehicle_id'] == vehicle].sort_values(by='sec').reset_index(drop=True).copy()\n",
    "        for index, row in filtData.iterrows():\n",
    "            if (haversine(ikea, (row['latitude'], row['longitude'])) < 1500):\n",
    "                vanStartTime[vehicle] = row['sec']\n",
    "                break\n",
    "    return vanStartTime\n",
    "\n",
    "def selectSimDate(simulationDate, riderData, requestsToConsider):\n",
    "    westBusNodes = [249, 197, 221, 200, 238, 124, 107, 116, 122, 124, 63, 113, 104, 227, 163, 84, 157, 110, 186, 14, 204]\n",
    "    # Filter data to only include IKEA riders\n",
    "    dfIKEA = riderData[(riderData['date'] == simulationDate) & \\\n",
    "                       (riderData['ride_id'].isin(requestsToConsider)) & \\\n",
    "                       (riderData['vehicle'].isin([2008, 2064, 2068])) & \\\n",
    "                       (~riderData['origin_poi'].isin(westBusNodes)) & \\\n",
    "                       (~riderData['destination_poi'].isin(westBusNodes))].reset_index(drop=True)\n",
    "    \n",
    "    # A couple of nodes are not present in the graph, so we can replace missing nodes with nearby nodes\n",
    "    dfIKEA[['origin_poi','destination_poi']] = dfIKEA[['origin_poi','destination_poi']].replace(46, 39)\n",
    "    dfIKEA[['origin_poi','destination_poi']] = dfIKEA[['origin_poi','destination_poi']].replace(33, 3)\n",
    "    #dfIKEA[['origin_poi','destination_poi']] = dfIKEA[['origin_poi','destination_poi']].replace(7, 214)\n",
    "    # This was visited once during a 4 month period, so we can drop this\n",
    "    dfIKEA1 = dfIKEA[(dfIKEA['origin_poi'] != 67) & (dfIKEA['destination_poi'] != 67) & \\\n",
    "                     (dfIKEA['origin_poi'] != 7) & (dfIKEA['destination_poi'] != 7) & \\\n",
    "                     (dfIKEA['origin_poi'] != 275) & (dfIKEA['destination_poi'] != 275)].copy()\n",
    "    \n",
    "    print(f'Count of trips dropped because node was not present in graph: {len(dfIKEA) - len(dfIKEA1)}') \n",
    "    dfIKEA2 = dfIKEA1[['ride_id','date','vehicle','origin_timestamp','timePeriod1','orig_sec','pending_sec', \\\n",
    "                       'origin_poi','destination_poi','od_pair', 'USE_orig_lat',\n",
    "                       'USE_orig_long', 'USE_dest_lat', 'USE_dest_long']].sort_values(by='origin_timestamp').copy()\n",
    "    return dfIKEA2\n",
    "\n",
    "# Create a list of rider objects to serve during the day\n",
    "def createDailyRiderList(riderData):\n",
    "    riderList = []\n",
    "    for i in range(len(riderData)):\n",
    "        riderList.append(rider(riderData['ride_id'].iloc[i], riderData['orig_sec'].iloc[i], \n",
    "                               riderData['pending_sec'].iloc[i], riderData['origin_poi'].iloc[i], \n",
    "                               riderData['destination_poi'].iloc[i], riderData['timePeriod1'].iloc[i],\n",
    "                               riderData['USE_orig_lat'].iloc[i], riderData['USE_orig_long'].iloc[i],\n",
    "                               riderData['USE_dest_lat'].iloc[i], riderData['USE_dest_long'].iloc[i]))\n",
    "    # create a list of riders that need to be served where riders can be removed throughout the day\n",
    "    remainingRiders = riderList.copy()\n",
    "    return riderList, remainingRiders\n",
    "\n",
    "# Get dictionary of IKEA vehicles { vehID : startTime }\n",
    "def getIkeaDict(vehDict):\n",
    "    newDict = dict()\n",
    "    for key, value in vehDict.items():\n",
    "        if (key in [1237, 1533, 1535]):\n",
    "            newDict[key] = value\n",
    "    return newDict\n",
    "\n",
    "def storeSimulationResults(dailyRiders, riderData, date):\n",
    "    # Filter original rider data\n",
    "    dfVan = riderData[(riderData['date'] == date)].copy()\n",
    "    dfVan['origin_timestamp'] = dfVan['origin_timestamp'].apply(pd.to_datetime, format='%Y-%m-%d %H:%M:%S')\n",
    "    # Convert new dataframe from the simulation results\n",
    "    a,b,c,d =[],[],[],[]\n",
    "    for rider in dailyRiders:\n",
    "        a.append(rider.van)\n",
    "        b.append(rider.pickupTime)\n",
    "        c.append(rider.dropoffTime)\n",
    "        d.append(rider.rideID)\n",
    "    x = pd.DataFrame(data = {'ride_id':d,'vanID':a, 'pickup_Sim':b,'dropoff_Sim':c})\n",
    "    mergeDF = pd.merge(dfVan, x, how = 'left', on = 'ride_id')\n",
    "    mergeDF1 = mergeDF[['ride_id','vehicle','vanID','origin_timestamp','orig_sec', 'pickup_Sim','dropoff_Sim','od_pair']]\n",
    "    mergeDF1.loc[:,'waitTimeSim'] = mergeDF1['pickup_Sim'] - mergeDF1['orig_sec']\n",
    "    mergeDF1.loc[:,'driveTimeSim'] = mergeDF1['dropoff_Sim'] - mergeDF1['pickup_Sim']\n",
    "    return mergeDF1\n",
    "\n",
    "def filtTrajData(trajData, simulDate):\n",
    "    traj = trajData[trajData['date'] == simulDate].reset_index(drop=True).copy()\n",
    "    vanStartTime = findIkeaStartTime(traj)\n",
    "    ikeaVehs = getIkeaDict(vanStartTime)\n",
    "    return ikeaVehs\n",
    "\n",
    "def runDaySimulation(riderData, date, timeDepTravTime, riderTimeDict, requestsDict, vehCount, timeWindow):\n",
    "    resultsDF = pd.DataFrame(columns = ['ride_id','vehicle','vanID','origin_timestamp','orig_sec','pickup_Sim',\\\n",
    "                                        'dropoff_Sim','od_pair','waitTimeSim','driveTimeSim'])\n",
    "    df = selectSimDate(date, riderData, requestsDict[date])\n",
    "    # =================== Run simulation Section ====================\n",
    "    # Compile list of riders for a specific day assigned to a specific van\n",
    "    dailyRiders, remainingRiders = createDailyRiderList(df)\n",
    "    \n",
    "    # For varying number of vans\n",
    "    if (vehCount == 0):\n",
    "        ikeaVehs = filtTrajData(trajData, date)\n",
    "        simStartTime = min([value for key, value in ikeaVehs.items()])\n",
    "    elif (vehCount == 1):\n",
    "        ikeaVehs = dict([(1535, 6*3600)])\n",
    "        simStartTime = 6*3600\n",
    "    elif (vehCount == 2):     \n",
    "        ikeaVehs = dict([(1535, 6*3600), (1533, 7*3600)])\n",
    "        simStartTime = 6*3600\n",
    "       \n",
    "    # ------------------------------------\n",
    "    # Inputs for simulation\n",
    "    waitCoeff = 0.75\n",
    "    driveCoeff = 0.25\n",
    "    deltaTime = 0*60\n",
    "    \n",
    "    sim = Sim(simStartTime, ikeaVehs, remainingRiders, timeDepTravTime, riderTimeDict, waitCoeff, driveCoeff, timeWindow) \n",
    "    while (sim.time <= 24*3600-60):\n",
    "        # Assign working vans based on their start times\n",
    "        sim.activateVans()\n",
    "        sim.assignRiderToVan()\n",
    "        sim.nextTrip()\n",
    "        sim.moveVans()\n",
    "        sim.step()\n",
    "\n",
    "    storedResults = storeSimulationResults(dailyRiders, df, date)\n",
    "    return storedResults\n",
    "\n",
    "# Run simulation for multiple dates\n",
    "def runSimulationForMultipleDates(trajData, riderData, dates, riderTimeDict, requestsDict, vehCount, timeWindow):\n",
    "    count = 0\n",
    "    for simulDate in dates:\n",
    "        print(simulDate)\n",
    "        if (count == 0):\n",
    "            simulationResults = runDaySimulation(riderData, simulDate, timeDepTravTime, riderTimeDict, requestsDict, vehCount, timeWindow)\n",
    "            count += 1\n",
    "        else:\n",
    "            simulationResults1 = runDaySimulation(riderData, simulDate, timeDepTravTime, riderTimeDict, requestsDict, vehCount, timeWindow)\n",
    "            simulationResults = simulationResults.append([simulationResults1],sort=True)\n",
    "    return simulationResults\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run simulation for dates in July 2019\n",
    "simulDates = ['2019-07-01','2019-07-03','2019-07-05',\\\n",
    "             '2019-07-08','2019-07-09','2019-07-10','2019-07-11','2019-07-12',\\\n",
    "             '2019-07-15','2019-07-16','2019-07-17','2019-07-18','2019-07-19',\\\n",
    "             '2019-07-22','2019-07-23','2019-07-24','2019-07-25','2019-07-26']\n",
    "\n",
    "vehCount = 2\n",
    "timeWindow = 0*60\n",
    "simulationResults = runSimulationForMultipleDates(trajData, riderData, simulDates, riderTimeDict, requestsDict, vehCount, timeWindow)\n",
    "\n",
    "#For multiple vans\n",
    "# i = 0\n",
    "# for vehCount in [1,2,3]:\n",
    "#     print(vehCount)\n",
    "#     if (i == 0):\n",
    "#         simulationResults = runSimulationForMultipleDates(trajData, riderData, simulDates, riderTimeDict, requestsDict, vehCount, timeWindow)\n",
    "#         simulationResults.loc[:, 'vanCount'] = vehCount\n",
    "#     else:\n",
    "#         simulationResults1 = runSimulationForMultipleDates(trajData, riderData, simulDates, riderTimeDict, requestsDict, vehCount,timeWindow)\n",
    "#         simulationResults1.loc[:, 'vanCount'] = vehCount\n",
    "#         simulationResults = simulationResults.append([simulationResults1],sort=True)\n",
    "#     i += 1\n",
    "\n",
    "#simulationResults.to_csv('1van.csv')\n",
    "#simulationResults.to_csv('USE_1van_uber_6min.csv')\n",
    "#simulationResults.to_csv('USE_2van.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code block is used to post-process data to include TNC assignments. During the simulation, a rider is assigned a TNC if their estimated wait time > wait time threshold defined in model. Wait and drive time are then added to results for TNC trips based on travel time graph and average wait times for Pittsburgh for Uber."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in simulation results\n",
    "# For 1 van case\n",
    "van_1_uber = pd.read_csv('USE_1van_uber_6min.csv')\n",
    "van_1_uber.loc[:,'type'] = 1\n",
    "van_1_uber.loc[:,'ones'] = 0\n",
    "# For 2 van case\n",
    "van_2 = pd.read_csv('USE_2van.csv')\n",
    "van_2.loc[:,'type'] = 2\n",
    "# For uber only case\n",
    "uber_only = van_2[['ride_id','od_pair','orig_sec','origin_timestamp']].copy()\n",
    "uber_only.loc[:,'type'] = 3\n",
    "uber_only.loc[:,'waitTimeSim'] = 5*60\n",
    "uber_only.loc[:,'driveTimeSim'] = 0\n",
    "uber_only.loc[:,'vanID'] = 'Uber'\n",
    "new = uber_only['od_pair'].str.split(',', n = 1, expand = True) \n",
    "uber_only['orig'] = new[0]\n",
    "uber_only['dest'] = new[1]\n",
    "uber_only['dest'] = uber_only['dest'].str.strip()\n",
    "uber_only[['orig','dest']] = uber_only[['orig','dest']].replace('46', '39')\n",
    "uber_only[['orig','dest']] = uber_only[['orig','dest']].replace('33', '3')\n",
    "\n",
    "def getTimePeriod(timeString):\n",
    "        timeInterval = 15\n",
    "        timePeriod = dt.datetime.strptime(timeString, '%H:%M:%S').time()\n",
    "        timePeriod = str(timePeriod.replace(minute = timeInterval*(timePeriod.minute//timeInterval), second = 0))\n",
    "        return timePeriod\n",
    "    \n",
    "def convertSecondsToTimeString(seconds):\n",
    "    hours = str(int(seconds//3600))\n",
    "    minutes = str(int((seconds%3600)//60))\n",
    "    if len(hours) < 2:\n",
    "        hours = '0' + hours\n",
    "    if len(minutes) < 2:\n",
    "        minutes = '0' + minutes\n",
    "    secs = '00'\n",
    "    return ':'.join([hours, minutes, secs])\n",
    "\n",
    "# For Uber + Van case\n",
    "for i in range(len(van_1_uber)):\n",
    "    if (van_1_uber['vanID'].iloc[i] == 'Uber'):\n",
    "        van_1_uber['pickup_Sim'].iloc[i] = van_1_uber['orig_sec'].iloc[i] + 5*60\n",
    "        van_1_uber['waitTimeSim'].iloc[i] = 5*60\n",
    "        van_1_uber['ones'].iloc[i] = 1\n",
    "        timeString = convertSecondsToTimeString(uber_only['orig_sec'].iloc[i])\n",
    "        timePeriod = getTimePeriod(timeString)\n",
    "        van_1_uber['driveTimeSim'].iloc[i] = nx.shortest_path_length(timeDepTravTime[timePeriod], \\\n",
    "                                                                 source = int(uber_only['orig'].iloc[i]), \\\n",
    "                                                                 target = int(uber_only['dest'].iloc[i]), \\\n",
    "                                                                 weight = 'median_x') \n",
    "\n",
    "# For Uber Only Case\n",
    "for i in range(len(uber_only)):\n",
    "    timeString = convertSecondsToTimeString(uber_only['orig_sec'].iloc[i])\n",
    "    timePeriod = getTimePeriod(timeString)\n",
    "    uber_only['driveTimeSim'].iloc[i] = nx.shortest_path_length(timeDepTravTime[timePeriod], \\\n",
    "                                                             source = int(uber_only['orig'].iloc[i]), \\\n",
    "                                                             target = int(uber_only['dest'].iloc[i]), \\\n",
    "                                                             weight = 'median_x')\n",
    "mergeDF1 = van_2.append([van_1_uber, uber_only], sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code block is to compute agency costs for each TNC trip based on Uber costs estimates for the region. The cost is determined by a function that includes driving distance, driving time, and base fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "travDist = pd.read_csv('Robinson_Trav_Dist.csv')\n",
    "\n",
    "def distDict(data):\n",
    "    storeDict = dict()\n",
    "    for i in range(len(data)):\n",
    "        orig = data['Orig_Node'].iloc[i]\n",
    "        dest = data['Dest_Node'].iloc[i]\n",
    "        storeDict[f'{orig}, {dest}'] = data['dist'].iloc[i]\n",
    "        storeDict[f'{dest}, {orig}'] = data['dist'].iloc[i]\n",
    "    return storeDict\n",
    "\n",
    "def calcCost(timeMin, distMile):\n",
    "    minFare = 8\n",
    "    baseFare = 1.43\n",
    "    bookingFee = 2.5\n",
    "    cost = baseFare + bookingFee + (0.32*timeMin) + (0.87*distMile)\n",
    "    totalFee = max(minFare, cost)\n",
    "    return totalFee\n",
    "    \n",
    "def addUberCosts(data, dist):\n",
    "    data.loc[:,'uberCost'] = 0\n",
    "    for i in range(len(data)):\n",
    "        if (data['vanID'].iloc[i] == 'Uber'):\n",
    "            timeMin = data['driveTimeSim'].iloc[i]/60\n",
    "            distMile = dist.get(data['od_pair'].iloc[i], 10)\n",
    "            data['uberCost'].iloc[i] = calcCost(timeMin, distMile)\n",
    "    return data\n",
    "    \n",
    "dist = distDict(travDist)\n",
    "df_costs = addUberCosts(mergeDF1, dist)\n",
    "df_costs['origin_timestamp'] = df_costs['origin_timestamp'].apply(pd.to_datetime, format='%Y-%m-%d %H:%M:%S')\n",
    "df_costs.loc[:,'date'] = df_costs['origin_timestamp'].dt.date.astype(str)\n",
    "df_costs.loc[:,'hour'] = df_costs['origin_timestamp'].dt.hour\n",
    "grouped = df_costs.groupby(['date','type'])['uberCost'].sum().reset_index()\n",
    "\n",
    "# Assign van costs ($51/hour worked)\n",
    "grouped.loc[:, 'totalCost'] = 0\n",
    "grouped.loc[grouped['type'] == 1, 'totalCost'] = grouped['uberCost'] + (18*51)\n",
    "grouped.loc[grouped['type'] == 2, 'totalCost'] = (14*51) + (17*51)\n",
    "grouped.loc[grouped['type'] == 3, 'totalCost'] = grouped['uberCost']\n",
    "grouped.loc[grouped['type'] == 1, 'Case'] = '1 Van + TNC'\n",
    "grouped.loc[grouped['type'] == 2, 'Case'] = '2 Vans'\n",
    "grouped.loc[grouped['type'] == 3, 'Case'] = 'TNC Only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process simulation data to format for plotting\n",
    "def processSimulationData(simulationResults1):\n",
    "    simulCase = simulationResults1[['ride_id','od_pair','origin_timestamp','vanID','pickup_Sim','dropoff_Sim','waitTimeSim', \\\n",
    "                                    'driveTimeSim','type']].copy()\n",
    "    simulCase['origin_timestamp'] = simulCase['origin_timestamp'].apply(pd.to_datetime, format='%Y-%m-%d %H:%M:%S')\n",
    "    simulCase.loc[:, 'hour'] = simulCase['origin_timestamp'].dt.hour\n",
    "    simulCase.loc[(simulCase['waitTimeSim'] < 0), 'waitTimeSim'] = 0\n",
    "    simulCase['waitTimeSim'] = simulCase['waitTimeSim'].astype(float)\n",
    "    simulCase['driveTimeSim'] = simulCase['driveTimeSim'].astype(float)\n",
    "    simulCase = simulCase.rename(columns={'waitTimeSim':'simulWaitTime', 'driveTimeSim':'simulDriveTime'})\n",
    "    simulCase.loc[:,'date'] = simulCase['origin_timestamp'].dt.date.astype(str)\n",
    "    simulCase.loc[:,'userCost'] = simulCase['simulWaitTime']*0.75 + simulCase['simulDriveTime']*0.25\n",
    "    return simulCase\n",
    "\n",
    "#plotBaseCaseData = processBaseCaseData(baseCaseResults)\n",
    "plotSimulData = processSimulationData(mergeDF1)\n",
    "#mergeResults = pd.merge(plotSimulData, plotBaseCaseData, how = 'left', on = 'ride_id')\n",
    "plotting = plotSimulData[['od_pair','hour','simulWaitTime','simulDriveTime','type','userCost']].groupby(['hour','type']).sum()/len(simulDates)\n",
    "plotting = plotting.reset_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('Research': conda)",
   "language": "python",
   "name": "python37464bitresearchconda5411d0b8105349948f71467381537ce8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
